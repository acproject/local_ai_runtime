# LLamaCpp Agent Server

åŸºäº llama.cpp çš„é«˜æ€§èƒ½ Agent æœåŠ¡å™¨ï¼Œæ”¯æŒå·¥å…·è°ƒç”¨ï¼ˆFunction Callingï¼‰ï¼Œå…¼å®¹ OpenAI API æ ¼å¼ã€‚

## ç‰¹æ€§

- **ğŸ”§ å·¥å…·è°ƒç”¨ï¼ˆFunction Callingï¼‰**ï¼šæ”¯æŒ JSON Schema å®šä¹‰çš„å·¥å…·ï¼Œè‡ªåŠ¨è½¬æ¢ä¸º GBNF è¯­æ³•çº¦æŸ
- **ğŸš€ é«˜æ€§èƒ½**ï¼šåŸºäº llama.cppï¼Œæ”¯æŒ Metal GPU åŠ é€Ÿï¼ˆmacOSï¼‰
- **ğŸŒ OpenAI å…¼å®¹ API**ï¼šå…¼å®¹ `/v1/chat/completions` ç­‰æ ‡å‡†ç«¯ç‚¹
- **ğŸ“ æµå¼å“åº”**ï¼šæ”¯æŒ SSE æµå¼è¾“å‡ºï¼ˆå¼€å‘ä¸­ï¼‰
- **ğŸ”„ å¯¹è¯ç®¡ç†**ï¼šè‡ªåŠ¨ç»´æŠ¤å¤šè½®å¯¹è¯å†å²
- **âš¡ C++23 ç°ä»£ä»£ç **ï¼šä½¿ç”¨ `std::expected`ã€`std::format` ç­‰ç°ä»£ç‰¹æ€§

## å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- **macOS**: Xcode 15+ (æ”¯æŒ C++23)
- **Linux**: GCC 13+ æˆ– Clang 17+
- **CMake**: 3.20+
- **Git**: ç”¨äºå­æ¨¡å—

### æ„å»º

```bash
# å…‹éš†ä»“åº“
git clone <repository-url>
cd llama_cpp_agent

# åˆå§‹åŒ–å­æ¨¡å—
git submodule update --init --recursive

# æ„å»º
mkdir build && cd build
cmake .. -DCMAKE_BUILD_TYPE=Release
cmake --build . -j$(nproc)
```

### è¿è¡Œ

```bash
# ä¸‹è½½æ¨¡å‹ï¼ˆç¤ºä¾‹ä½¿ç”¨ Qwen2.5ï¼‰
wget https://huggingface.co/Qwen/Qwen2.5-7B-Instruct-GGUF/resolve/main/qwen2.5-7b-instruct-q4_k_m.gguf

# å¯åŠ¨æœåŠ¡å™¨
./llama_agent_server qwen2.5-7b-instruct-q4_k_m.gguf

# æœåŠ¡å™¨é»˜è®¤è¿è¡Œåœ¨ http://localhost:8080
```

## API ä½¿ç”¨

### å¥åº·æ£€æŸ¥

```bash
curl http://localhost:8080/health
```

### å¯¹è¯è¡¥å…¨

```bash
curl -X POST http://localhost:8080/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "llama-agent",
    "messages": [
      {"role": "user", "content": "Hello!"}
    ]
  }'
```

### å¸¦å·¥å…·è°ƒç”¨çš„å¯¹è¯

```bash
curl -X POST http://localhost:8080/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "llama-agent",
    "messages": [
      {"role": "user", "content": "What's the weather in Beijing?"}
    ],
    "tools": [
      {
        "type": "function",
        "function": {
          "name": "get_weather",
          "description": "Get weather information",
          "parameters": {
            "type": "object",
            "properties": {
              "location": {"type": "string"}
            },
            "required": ["location"]
          }
        }
      }
    ]
  }'
```

## é¡¹ç›®ç»“æ„

```
llama_cpp_agent/
â”œâ”€â”€ include/llama_agent/      # å…¬å…±å¤´æ–‡ä»¶
â”‚   â”œâ”€â”€ agent_runtime.hpp     # Agent è¿è¡Œæ—¶æ ¸å¿ƒ
â”‚   â”œâ”€â”€ gbnf_generator.hpp    # JSON Schema â†’ GBNF
â”‚   â”œâ”€â”€ llama_wrapper.hpp     # llama.cpp å°è£…
â”‚   â”œâ”€â”€ tool_manager.hpp      # å·¥å…·ç®¡ç†
â”‚   â”œâ”€â”€ tool_call_parser.hpp  # å·¥å…·è°ƒç”¨è§£æ
â”‚   â”œâ”€â”€ conversation.hpp      # å¯¹è¯å†å²
â”‚   â””â”€â”€ http_server.hpp       # HTTP æœåŠ¡å™¨
â”œâ”€â”€ src/                      # å®ç°æ–‡ä»¶
â”œâ”€â”€ tests/                    # å•å…ƒæµ‹è¯•
â”œâ”€â”€ extern/                   # ç¬¬ä¸‰æ–¹ä¾èµ–
â”‚   â”œâ”€â”€ llama.cpp/           # llama.cpp å­æ¨¡å—
â”‚   â”œâ”€â”€ cpp-httplib/         # HTTP æœåŠ¡å™¨åº“
â”‚   â””â”€â”€ json/                # nlohmann/json
â””â”€â”€ build/                    # æ„å»ºç›®å½•
```

## æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           HTTP API Server               â”‚
â”‚     (OpenAI-compatible endpoints)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Agent Runtime                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  State   â”‚  â”‚  Tool    â”‚  â”‚  Conv  â”‚â”‚
â”‚  â”‚ Machine  â”‚  â”‚  Manager â”‚  â”‚History â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        GrammarGenerator                 â”‚
â”‚    (JSON Schema â†’ GBNF)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          LlamaWrapper                   â”‚
â”‚    (llama.cpp C++ Wrapper)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## æ ¸å¿ƒç»„ä»¶

### 1. AgentRuntime

ç®¡ç†å¯¹è¯æµç¨‹ã€çŠ¶æ€æœºå’Œå·¥å…·è°ƒç”¨ï¼š

```cpp
AgentRuntime runtime(
    std::make_unique<LlamaWrapper>(config),
    std::make_unique<ToolManager>(),
    agentConfig
);

// æ³¨å†Œå·¥å…·
runtime.registerTool(toolDef, [](const nlohmann::json& params) {
    return nlohmann::json{{"temperature", 25.0}};
});

// å¤„ç†æ¶ˆæ¯
auto response = runtime.processMessage("What's the weather?");
```

### 2. GrammarGenerator

å°† JSON Schema è½¬æ¢ä¸º GBNF è¯­æ³•ï¼š

```cpp
GrammarGenerator gen;
auto grammar = gen.generateFromSchema(schema);
auto toolGrammar = gen.generateToolCallGrammar(tools);
```

### 3. ToolCallParser

è§£æ LLM è¾“å‡ºçš„å·¥å…·è°ƒç”¨ï¼š

```cpp
ToolCallParser parser;
auto toolCalls = parser.parse(llmResponse);
for (const auto& call : toolCalls) {
    auto result = executeTool(call);
}
```

## é…ç½®é€‰é¡¹

| é€‰é¡¹ | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `systemPrompt` | string | - | ç³»ç»Ÿæç¤ºè¯ |
| `maxIterations` | int | 10 | æœ€å¤§å·¥å…·è°ƒç”¨è¿­ä»£æ¬¡æ•° |
| `maxTokensPerResponse` | int | 512 | æ¯æ¬¡å“åº”æœ€å¤§ token æ•° |
| `temperature` | float | 0.7 | é‡‡æ ·æ¸©åº¦ |
| `enableToolUse` | bool | true | å¯ç”¨å·¥å…·è°ƒç”¨ |
| `retryAttempts` | int | 3 | é”™è¯¯é‡è¯•æ¬¡æ•° |

## æµ‹è¯•

```bash
# è¿è¡Œæµ‹è¯•
cd build
ctest --output-on-failure

# è¿è¡Œç‰¹å®šæµ‹è¯•
./tests/test_tool_call_parser
```

## å¼€å‘è®¡åˆ’

- [x] Phase 1: é¡¹ç›®éª¨æ¶æ­å»º
- [x] Phase 2: æ ¸å¿ƒç»„ä»¶å¼€å‘
- [x] Phase 3: Agent Runtime å®Œå–„
- [ ] Phase 4: æµ‹è¯•ä¸æ–‡æ¡£
  - [x] åŸºç¡€å•å…ƒæµ‹è¯•
  - [ ] é›†æˆæµ‹è¯•
  - [x] API æ–‡æ¡£
- [ ] Phase 5: æ€§èƒ½ä¼˜åŒ–
  - [ ] æ‰¹å¤„ç†æ¨ç†
  - [ ] æ¨¡å‹é‡åŒ–æ”¯æŒ
  - [ ] å¹¶å‘è¯·æ±‚å¤„ç†

## æŠ€æœ¯æ ˆ

- **C++23**: `std::expected`, `std::format`, concepts
- **llama.cpp**: æ¨ç†åç«¯
- **cpp-httplib**: HTTP æœåŠ¡å™¨
- **nlohmann/json**: JSON å¤„ç†
- **GoogleTest**: æµ‹è¯•æ¡†æ¶

## è®¸å¯è¯

MIT License

## è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## è‡´è°¢

- [llama.cpp](https://github.com/ggml-org/llama.cpp) - ä¼˜ç§€çš„ LLM æ¨ç†åº“
- [nlohmann/json](https://github.com/nlohmann/json) - ç°ä»£ C++ JSON åº“
- [cpp-httplib](https://github.com/yhirose/cpp-httplib) - C++ HTTP åº“
