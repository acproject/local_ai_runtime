## 你现在可以怎么测（建议顺序）

## 0) 前置检查
- 目标：确认 runtime、mock MCP、以及（可选）Ollama 三者的连通性。
- 运行态端口默认：runtime `127.0.0.1:8080`；mock MCP 例子：`9000/9001`。

## 1) 一键回归（推荐）
- 运行：[regression.py](file:///Users/acproject/workspace/cpp_projects/local-ai-runtime/tools/regression.py)
- 做什么：自动启动 mock MCP（lsp 模式）+ runtime（临时端口），然后验证：
  - `/internal/refresh_mcp_tools` 能刷新并注册工具
  - `ide.read_file` 走通
  - `planner` 的 `max_rewrites` 能把坏 plan 重写为可执行 plan（并在 trace 中看到 plan_rewrites）
- 命令（示例）：
  - `python3 tools/regression.py --workspace-root /Users/acproject/workspace/cpp_projects/local-ai-runtime`

## 2) 手动验证（更直观，适合演示/排障）
### 2.1 启动 mock MCP
- echo 模式（可选）：
  - `python3 tools/mock_mcp_server.py --port 9000 --mode echo`
- lsp 模式（含 fs.read_file/fs.search/lsp.*）：
  - `python3 tools/mock_mcp_server.py --port 9001 --mode lsp`

### 2.2 启动 runtime（带工作区约束）
- 建议环境变量：
  - `MCP_HOSTS=http://127.0.0.1:9001/`
  - `RUNTIME_WORKSPACE_ROOT=/Users/acproject/workspace/cpp_projects/local-ai-runtime`
  - （可选）`RUNTIME_LISTEN_HOST=127.0.0.1` `RUNTIME_LISTEN_PORT=8080`
- 启动后先测 `/v1/models`：
  - `curl http://127.0.0.1:8080/v1/models`

### 2.3 刷新/检查 MCP 工具注入
- 刷新工具：
  - `curl -X POST http://127.0.0.1:8080/internal/refresh_mcp_tools`
- 预期：返回 JSON，含 `ok=true`、`servers>=1`、`registered>=5`（lsp 模式）。

### 2.4 测 LSP Facade 五类工具（ide.*）
- 你需要在请求体 tools 里显式声明允许调用的工具（allowlist）。示例（任选其一测通即可）：
  - `ide.read_file`：传 `path`（建议用相对路径如 `src/main.cpp`）
  - `ide.search`：传 `query` + 可选 `path`
  - `ide.diagnostics`：传 `uri`（file:// 或相对/绝对路径均可，都会被归一化到 workspace root 下）
  - `ide.hover / ide.definition`：传 `uri + line + character`
- 越界拦截（负例）：
  - `ide.read_file` 传 `/tmp/a.cpp` 或 `file:///tmp/a.cpp`
  - 预期：`{"ok":false,"error":"path is outside workspace root"}`

### 2.5 测 Planner v1（plan 校验 + 重写 + trace）
- 打开 trace：请求体加 `trace=true`
- 开启 planner：
  - `"planner": {"enabled": true, "max_plan_steps": 2, "max_rewrites": 1}`
- 预期：响应 header `x-runtime-trace` 里能看到：
  - `used_planner=true`
  - `plan`（最终执行的 plan 列表）
  - `plan_rewrites`（发生重写时 >0）
  - `tool_calls/tool_results`

## 3) SSE 流式验证（可选）
- 用 `curl -N` 测 `POST /v1/chat/completions` 且 `"stream": true`
- 重点看：
  - 是否按 OpenAI ChatCompletions SSE 形态输出 `data: {...}\n\n` 和最终 `[DONE]`
  - tool_calls.arguments 是否出现分片拼接（增量片段）

## 4) 出问题怎么定位
- 首选：把 `trace=true` 打开并抓 `x-runtime-trace`。
- MCP 问题：先 `POST /internal/refresh_mcp_tools` 看 errors 数组。
- 工作区越界：检查 `RUNTIME_WORKSPACE_ROOT` 是否正确、以及传入 path/uri 是否被归一化到 root 下。

如果你同意这个测试方案，我下一步可以把“手动 curl 用例”整理成一个 `tools/smoke.sh`（只读执行、无依赖）并加到开发计划的验收段落里，方便团队复制执行。